{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grading Feedback Cell\n",
    "75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4e6cefb0049d48a2f4648d752841bb06",
     "grade": false,
     "grade_id": "cell-b038e38b5e3072a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Willard Williamson <wewillia@syr.edu>\n",
    "- Faculty Assistant: Palaniappan Muthukkaruppan\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers from your classmates.  Short code snippets are allowed from the internet.  Any code is allowed from the class text books or class provided code.__\n",
    "- Please do not change the file names. The FAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and FAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spark and sparkcontext objects\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning: Use exclusively Spark 1.6 when asked to do so and Spark 2.0 (dataframes) only in the last question. Do not use Pandas at all in this assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Data cleaning and basic analyses\n",
    "\n",
    "In this part, you will learn to read data from non-standard formats, clean data, and produce some basic analysis of it.\n",
    "\n",
    "We will use Spark 1.6 (`sparkContext` on variable `sc`) to load text files from which we will extract features that are predictive of a target value. Unfortunately, the data is stored in some non-standard format where each line contains the customer index, the feature index, and the value of the feature for that customer. Similarly, the target files contain in each line the customer index and the target value. We will load these files into two RDDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "52b18c5545e26c712a0ff9f85bf9e755",
     "grade": false,
     "grade_id": "cell-e8f7bc29c04e04e0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Adjust the following lines as needed to read the data files\n",
    "# If running on databricks, you will need to upload the data to databricks and then\n",
    "# adjust the file path as demonstrated in class.\n",
    "raw_features_rdd = sc.textFile('hw2_dataset_features.txt')\n",
    "raw_target_rdd = sc.textFile('hw2_dataset_targets.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An issue with the data is that there were problems transmitting the features and targets. If this happened, then a text `ERROR` or `ERROR TRANSFERRING` replaced the data. If you look at the first 10 values of the features and target RDD, you will see these types of lines:\n",
    "\n",
    "```python\n",
    "raw_features_rdd.take(10)\n",
    "```\n",
    "\n",
    "```\n",
    "['<customer_feature customer_id=0 feature_id=0>-0.57</customer_feature>',\n",
    " '<customer_feature customer_id=0 feature_id=1>-0.38</customer_feature>',\n",
    " '<customer_feature customer_id=0 feature_id=2>0.00</customer_feature>',\n",
    " '<customer_feature customer_id=0 feature_id=3>-0.07</customer_feature>',\n",
    " '<customer_feature customer_id=0 feature_id=4>-0.28</customer_feature>',\n",
    " '<customer_feature customer_id=0 feature_id=5>-0.79</customer_feature>',\n",
    " 'ERROR',\n",
    " '<customer_feature customer_id=0 feature_id=7>0.28</customer_feature>',\n",
    " '<customer_feature customer_id=0 feature_id=8>1.65</customer_feature>',\n",
    " '<customer_feature customer_id=0 feature_id=9>0.57</customer_feature>']\n",
    "```\n",
    "\n",
    "```python\n",
    "raw_target_rdd.take(35)\n",
    "```\n",
    "\n",
    "```\n",
    "['<customer_target customer_id=0>-252.49</customer_target>',\n",
    " '<customer_target customer_id=1>36.67</customer_target>',\n",
    " '<customer_target customer_id=2>138.02</customer_target>',\n",
    " '<customer_target customer_id=3>-429.54</customer_target>',\n",
    " '<customer_target customer_id=4>-18.23</customer_target>',\n",
    " '<customer_target customer_id=5>-5.52</customer_target>',\n",
    " '<customer_target customer_id=6>-31.96</customer_target>',\n",
    " 'ERROR TRANSFERRING',\n",
    " 'ERROR TRANSFERRING',\n",
    " '<customer_target customer_id=9>-111.88</customer_target>']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try it yourself: raw_features_rdd.take(10) and raw_target_rdd.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1 (10 pts):\n",
    "\n",
    "Filter out the lines that contain errors and store them in `raw_features2_rdd` and `raw_targets_rdd` respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7258f0792387b2cdd0c4bb92886496ad",
     "grade": false,
     "grade_id": "cell-626aab3709c46ced",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create raw_features2_rdd and raw_targets2_rdd below\n",
    "# YOUR CODE HERE\n",
    "raw_features2_rdd = raw_features_rdd.filter(lambda x: 'ERROR' not in x)\n",
    "raw_target2_rdd = raw_target_rdd.filter(lambda x: 'ERROR' not in x)\n",
    "# raise NotImplementedError()\n",
    "# method 2:subtract the line containing 'ERROR'\n",
    "# error_features_rdd = raw_features_rdd.filter(lambda x: 'ERROR' in x)\n",
    "# raw_features2_rdd = raw_features_rdd.subtract(error_features_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95036\n",
      "8968\n"
     ]
    }
   ],
   "source": [
    "# check that things work\n",
    "print(raw_features2_rdd.count())\n",
    "print(raw_target2_rdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "34b858b2a4dae4c0c6569a235758d7e7",
     "grade": true,
     "grade_id": "cell-16fe9b731c74bdb1",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"10 pts: Check that the lines are properly discarded\"\"\"\n",
    "assert raw_features2_rdd.count() == 95036\n",
    "assert raw_target2_rdd.count() == 8968"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2 (10 pts):\n",
    "You will further process `raw_features2_rdd` such that you will create a key-value RDD of the following form: the key is the customer index as an integer and the value is a dictionary whose key is a string `f_0`, `f_1`, ..., `f_9` for feature index 0, 1, ... 9, respetively, and the value is a floating point number of the feature value. \n",
    "\n",
    "Define a function `map_features2` that performs such key-value pair creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1ac97b311e4bedac55e3aee7cf0a78b3",
     "grade": false,
     "grade_id": "cell-6a8bd9ba37f02ccc",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def map_features2(line):\n",
    "    # YOUR CODE HERE\n",
    "    line = line.split('=')                 # split the string, using '='\n",
    "    customer_id = line[1].split(' ')[0]    # customer_id is the first element in the second part of line\n",
    "    feature = line[2].split('>')           # feature is the third part of split line\n",
    "                                           # e.g 'feature_id=0>-0.79</customer_feature' are split by '>'\n",
    "    feature_id = feature[0]                # the first part of feature is feature_id\n",
    "    customer_feature = feature[1].split(\"<\")[0] # the second part of feature, before the < is customer_feature.\n",
    "                                                # e.g '-0.79</customer_feature'\n",
    "    key_value = [int(customer_id), {'f_'+str(feature_id):float(customer_feature)}] # define the data type of the result.\n",
    "    return (key_value)\n",
    "    # raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, for the input element:\n",
    "\n",
    "`'<customer_feature customer_id=4 feature_id=0>-0.79</customer_feature>'`\n",
    "\n",
    "it should generate\n",
    "```python\n",
    "[4, {'f_0': -0.79}]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, {'f_0': -0.57}],\n",
       " [0, {'f_1': -0.38}],\n",
       " [0, {'f_2': 0.0}],\n",
       " [0, {'f_3': -0.07}],\n",
       " [0, {'f_4': -0.28}],\n",
       " [0, {'f_5': -0.79}],\n",
       " [0, {'f_7': 0.28}],\n",
       " [0, {'f_8': 1.65}],\n",
       " [0, {'f_9': 0.57}],\n",
       " [1, {'f_0': 0.5}]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test it here\n",
    "raw_features2_rdd.\\\n",
    "    map(map_features2).\\\n",
    "    take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d152e2bbb8f36de1ff57cf05b404ff89",
     "grade": true,
     "grade_id": "cell-185fc07f367e8eb6",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"10 pts: Check that the new raw_features2_rdd and raw_target2_rdd RDDs are correct\"\"\"\n",
    "# key is an integer\n",
    "np.testing.assert_equal(type(raw_features2_rdd.map(map_features2).first()[0]), int)\n",
    "# value is a dictionary\n",
    "np.testing.assert_equal(type(raw_features2_rdd.map(map_features2).first()[1]), dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.3 (5 pts):\n",
    "\n",
    "You will create a function `map_target2` that will be applied to `raw_target2_rdd`. This function will create key-value pair where the key is the customer index as an integer and the value is the floating point representation of the target. Assign the resulting RDD to `raw_target3_rdd`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '-252.49</customer_target', '']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = raw_target2_rdd.first()\n",
    "key_value = line.split('=')[1].split('>')\n",
    "key_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<customer_target customer_id=0>-252.49</customer_target>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "35c7e987523d093eba540b64dffb0e78",
     "grade": false,
     "grade_id": "cell-0a9dc80ecf0c1b6a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def map_target2(line):\n",
    "    # YOUR CODE HERE\n",
    "    key_value = line.split('=')[1].split('>')  # split the string using '=', keep the second part\n",
    "                                               # split the second part using \">\"\n",
    "    key = key_value[0]                         # the first part of key_value is customer_id                                          \n",
    "    value = key_value[1].split('<')[0]         # the second part of key_value, before the < is customer_target.\n",
    "    return(int(key), float(value))\n",
    "    # raise NotImplementedError()\n",
    "\n",
    "# make the assignment here\n",
    "raw_target3_rdd = raw_target2_rdd.map(map_target2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample of results:\n",
    "\n",
    "```python\n",
    "raw_target2_rdd.map(map_target2).sortByKey().take(5)\n",
    "```\n",
    "\n",
    "```\n",
    "[(0, -252.49), (1, 36.67), (2, 138.02), (3, -429.54), (4, -18.23)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, -252.49), (1, 36.67), (2, 138.02), (3, -429.54), (4, -18.23)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try it yourself\n",
    "raw_target2_rdd.map(map_target2).sortByKey().take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3a9dcf95e4643d24fa6987f060f6b479",
     "grade": true,
     "grade_id": "cell-00147973f05ae1e7",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"5 pts: Check that raw_target3_rdd contains the right values\"\"\"\n",
    "# check types\n",
    "np.testing.assert_equal(type(raw_target3_rdd.keys().first()), int)\n",
    "np.testing.assert_equal(type(raw_target3_rdd.values().first()), float)\n",
    "# the sum of all targets\n",
    "np.testing.assert_approx_equal(raw_target3_rdd.values().sum(), -179351.71, significant=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.4 (10 pts):\n",
    "\n",
    "In this question, you will use map reduce to produce an RDD of key-value pairs where the key is the customer index and the value is a dictionairy with all the features and values associated with that customer. Notice that the map part of the map-reduce is already defined by `map_features2` on `raw_features2_rdd`. Therefore, define the proper `reduce_features2` function to produce the desired results. Create a RDD named `raw_features3_rdd` with the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bf88749fa6073bb62b123416b87783c6",
     "grade": false,
     "grade_id": "cell-c51c5ed026c36cb7",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def reduce_features2(v1, v2):\n",
    "    # YOUR CODE HERE\n",
    "    return ({**v1, **v2})  # **kwargs unpacks the contents of a dictionary into the function call.\n",
    "    # raise NotImplementedError()\n",
    "\n",
    "# Apply mapreduce to produce the raw_features3_rdd from raw_features2_rdd\n",
    "# YOUR CODE HERE\n",
    "raw_features3_rdd=raw_features2_rdd.map(map_features2).reduceByKey(reduce_features2)\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the map reduce should produce the following example result:\n",
    "```python\n",
    "raw_features3_rdd.sortByKey().take(2)\n",
    "```\n",
    "\n",
    "```console\n",
    "[(0,\n",
    "  {'f_0': -0.57,\n",
    "   'f_1': -0.38,\n",
    "   'f_2': 0.0,\n",
    "   'f_3': -0.07,\n",
    "   'f_4': -0.28,\n",
    "   'f_5': -0.79,\n",
    "   'f_7': 0.28,\n",
    "   'f_8': 1.65,\n",
    "   'f_9': 0.57}),\n",
    " (1,\n",
    "  {'f_0': 0.5,\n",
    "   'f_1': 0.8,\n",
    "   'f_2': -0.49,\n",
    "   'f_3': 0.25,\n",
    "   'f_4': 0.37,\n",
    "   'f_5': 0.73,\n",
    "   'f_6': -0.43,\n",
    "   'f_7': 0.89,\n",
    "   'f_8': -1.85,\n",
    "   'f_9': -0.44})]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ed95bb2f5c17ad9f9fd2528d2a551730",
     "grade": true,
     "grade_id": "cell-f74bab4029291e96",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"10 pts: Check that raw_features3_rdd has the correct format and values. There could be hidden tests!\"\"\"\n",
    "# key is an integer\n",
    "np.testing.assert_equal(type(raw_features3_rdd.first()[0]), int)\n",
    "# value is a dictionary\n",
    "np.testing.assert_equal(type(raw_features3_rdd.first()[1]), dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.5 (20 pts):\n",
    "\n",
    "Join the two RDDs `raw_target3_rdd` and `raw_features3_rdd` to create an RDD with elements of the form\n",
    "\n",
    "`[customer_index, (target, feature_dict)]`\n",
    "\n",
    "where `target` comes from `raw_target3_rdd`, and `feature_dict` is the dictionary with features from `raw_features3_rdd`.\n",
    "\n",
    "Assign to `rdd_complete` a filtered version of the join for customers who have all 10 features and a target.\n",
    "\n",
    "Finally use `rdd_complete_rows` to create an RDD of `Row` objects where you map each entry to the following format:\n",
    "\n",
    "`Row(customer_index,  f_0,  f_1,  f_2,  f_3,  f_4,  f_5,  f_6,  f_7,  f_8,  f_9, target)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, from `rdd_complete`:\n",
    "\n",
    "```python\n",
    "rdd_complete.sortByKey().first()\n",
    "```\n",
    "should return\n",
    "```\n",
    "(1,\n",
    " (36.67,\n",
    "  {'f_0': 0.5,\n",
    "   'f_1': 0.8,\n",
    "   'f_2': -0.49,\n",
    "   'f_3': 0.25,\n",
    "   'f_4': 0.37,\n",
    "   'f_5': 0.73,\n",
    "   'f_6': -0.43,\n",
    "   'f_7': 0.89,\n",
    "   'f_8': -1.85,\n",
    "   'f_9': -0.44}))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "758a59186ed17064075d698f947a4784",
     "grade": false,
     "grade_id": "cell-225a18b6658c1598",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create rdd_complete here\n",
    "# YOUR CODE HERE\n",
    "rdd_complete = raw_target3_rdd.join(raw_features3_rdd.filter(lambda x: len(x[1])==10))\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "57ff1356246ff36cf7c81d5fe8b33b87",
     "grade": true,
     "grade_id": "cell-47b082a8f8d07296",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"10 pts: Test if `rdd1` has the right data. Remember that there could be hidden tests!\"\"\"\n",
    "# number of elements expected\n",
    "np.testing.assert_equal(rdd_complete.count(), 5379)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e518b98058f857ef947f11afe2774230",
     "grade": false,
     "grade_id": "cell-63a9f734c2e8d9f1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# here define the function to_row that a Row object for an entry of rdd_complete\n",
    "def to_row(e):\n",
    "    row_data = Row(                 # e=[customer_index, (target, feature_dict)]\n",
    "        customer_index=e[0],        # customer_index is the first element of e\n",
    "        **{'f_'+str(i): list(e[1][1].values())[i] for i in range(10)},   # e[1][1].values() is all the values in the dictionay features\n",
    "                                                                         # e[1][1].values() is dict_values type, so convert it to list and take the ith value for feature i\n",
    "        target=e[1][0])             # target is the first part of the (target, feature_dict)\n",
    "    return row_data\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "\n",
    "complete_df = rdd_complete.map(to_row).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "|customer_index|  f_0|  f_1|  f_2|  f_3|  f_4|  f_5|  f_6|  f_7|  f_8|  f_9| target|\n",
      "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "|             1|  0.5|  0.8|-0.49| 0.25| 0.37| 0.73|-0.43| 0.89|-1.85|-0.44|  36.67|\n",
      "|             3| 0.14|-0.87|-0.94| 0.09|-0.69|-0.29|-0.45| -0.6|-1.28|-0.38|-429.54|\n",
      "|             4|-0.79|-0.28|-0.26| 0.28|-0.17|-0.51| 0.44|-0.62| 1.82|-0.35| -18.23|\n",
      "|             5|-0.11| 0.86| -1.3|-0.09|-0.12|-0.47| 0.05| 0.98|-1.59|  0.3|  -5.52|\n",
      "|             9| 0.57| 0.07|-0.31|-0.92|-0.26| -0.9|-0.06|-0.76| 1.39| 0.01|-111.88|\n",
      "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "rdd_complete.map(to_row).toDF().orderBy('customer_index').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2d8a63ee5a5324c0b86e37742630d9b7",
     "grade": true,
     "grade_id": "cell-a1f30aae3cf357e3",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts test that the creation of the row is successful\n",
    "assert rdd_complete.map(to_row).toDF()\n",
    "np.testing.assert_array_equal(rdd_complete.map(to_row).toDF().columns, \n",
    "              ['customer_index',\n",
    " 'f_0',\n",
    " 'f_1',\n",
    " 'f_2',\n",
    " 'f_3',\n",
    " 'f_4',\n",
    " 'f_5',\n",
    " 'f_6',\n",
    " 'f_7',\n",
    " 'f_8',\n",
    " 'f_9',\n",
    " 'target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.6 (20 pts):\n",
    "\n",
    "We will now use the `to_row` function created above to create a dataframe of the data `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e32c44443a35936770c76a2af3848e70",
     "grade": false,
     "grade_id": "cell-e81ad00df6011794",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df = rdd_complete.map(to_row).toDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the dataframe a bit:\n",
    "\n",
    "```python\n",
    "df.orderBy('customer_index').show(5)\n",
    "```\n",
    "\n",
    "```console\n",
    "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
    "|customer_index|  f_0|  f_1|  f_2|  f_3|  f_4|  f_5|  f_6|  f_7|  f_8|  f_9| target|\n",
    "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
    "|             1|  0.5|  0.8|-0.49| 0.25| 0.37| 0.73|-0.43| 0.89|-1.85|-0.44|  36.67|\n",
    "|             3| 0.14|-0.87|-0.94| 0.09|-0.69|-0.29|-0.45| -0.6|-1.28|-0.38|-429.54|\n",
    "|             4|-0.79|-0.28|-0.26| 0.28|-0.17|-0.51| 0.44|-0.62| 1.82|-0.35| -18.23|\n",
    "|             5|-0.11| 0.86| -1.3|-0.09|-0.12|-0.47| 0.05| 0.98|-1.59|  0.3|  -5.52|\n",
    "|             9| 0.57| 0.07|-0.31|-0.92|-0.26| -0.9|-0.06|-0.76| 1.39| 0.01|-111.88|\n",
    "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
    "only showing top 5 rows\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "|customer_index|  f_0|  f_1|  f_2|  f_3|  f_4|  f_5|  f_6|  f_7|  f_8|  f_9| target|\n",
      "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "|             1|  0.5|  0.8|-0.49| 0.25| 0.37| 0.73|-0.43| 0.89|-1.85|-0.44|  36.67|\n",
      "|             3| 0.14|-0.87|-0.94| 0.09|-0.69|-0.29|-0.45| -0.6|-1.28|-0.38|-429.54|\n",
      "|             4|-0.79|-0.28|-0.26| 0.28|-0.17|-0.51| 0.44|-0.62| 1.82|-0.35| -18.23|\n",
      "|             5|-0.11| 0.86| -1.3|-0.09|-0.12|-0.47| 0.05| 0.98|-1.59|  0.3|  -5.52|\n",
      "|             9| 0.57| 0.07|-0.31|-0.92|-0.26| -0.9|-0.06|-0.76| 1.39| 0.01|-111.88|\n",
      "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explore it yourself\n",
    "df.orderBy('customer_index').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subpackage `pyspark.ml.functions` (aliased as `fn` below) contains many common functions for data analysis. Find the function for computing the __correlation__ (the strength of the linear relationship between two variables) between two columns, the function for computing __absolute__ values, and create a data frame `correlations_df` that contains the following columns in the following order:\n",
    "\n",
    "1. `c0_target`: correlation between feature 0 and target\n",
    "1. `c1_target`: correlation between feature 1 and target\n",
    "1. `c2_target`: correlation between feature 2 and target\n",
    "1. `c3_target`: correlation between feature 3 and target\n",
    "1. `c4_target`: correlation between feature 4 and target\n",
    "1. `c5_target`: correlation between feature 5 and target\n",
    "1. `c6_target`: correlation between feature 6 and target\n",
    "1. `c7_target`: correlation between feature 7 and target\n",
    "1. `c8_target`: correlation between feature 8 and target\n",
    "1. `c9_target`: correlation between feature 9 and target\n",
    "1. `sig0`: boolean `true` if the absolute value of the correlation between feature 0 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig1`: boolean `true` if the absolute value of the correlation between feature 1 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig2`: boolean `true` if the absolute value of the correlation between feature 2 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig3`: boolean `true` if the absolute value of the correlation between feature 3 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig4`: boolean `true` if the absolute value of the correlation between feature 4 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig5`: boolean `true` if the absolute value of the correlation between feature 5 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig6`: boolean `true` if the absolute value of the correlation between feature 6 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig7`: boolean `true` if the absolute value of the correlation between feature 7 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig8`: boolean `true` if the absolute value of the correlation between feature 8 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig9`: boolean `true` if the absolute value of the correlation between feature 9 and target is greater than 0.5, `false` o.w.\n",
    "\n",
    "**Hint: Remember that you can pass a list of columns to `df.select`. You can create such list with list comprehension, saving a lot of code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the package functions as fn\n",
    "from pyspark.sql import functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply some function to the columns: df.select(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d50d7ffa26caed36ab9594774d715b63",
     "grade": false,
     "grade_id": "cell-12e8f5f6de39ae69",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c0_target</th>\n",
       "      <th>c1_target</th>\n",
       "      <th>c2_target</th>\n",
       "      <th>c3_target</th>\n",
       "      <th>c4_target</th>\n",
       "      <th>c5_target</th>\n",
       "      <th>c6_target</th>\n",
       "      <th>c7_target</th>\n",
       "      <th>c8_target</th>\n",
       "      <th>c9_target</th>\n",
       "      <th>sig0</th>\n",
       "      <th>sig1</th>\n",
       "      <th>sig2</th>\n",
       "      <th>sig3</th>\n",
       "      <th>sig4</th>\n",
       "      <th>sig5</th>\n",
       "      <th>sig6</th>\n",
       "      <th>sig7</th>\n",
       "      <th>sig8</th>\n",
       "      <th>sig9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00455</td>\n",
       "      <td>0.517542</td>\n",
       "      <td>0.242225</td>\n",
       "      <td>-0.027253</td>\n",
       "      <td>0.610934</td>\n",
       "      <td>-0.015062</td>\n",
       "      <td>0.576348</td>\n",
       "      <td>0.063349</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>-0.017158</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c0_target  c1_target  c2_target  c3_target  c4_target  c5_target  \\\n",
       "0    0.00455   0.517542   0.242225  -0.027253   0.610934  -0.015062   \n",
       "\n",
       "   c6_target  c7_target  c8_target  c9_target   sig0  sig1   sig2   sig3  \\\n",
       "0   0.576348   0.063349   0.007564  -0.017158  False  True  False  False   \n",
       "\n",
       "   sig4   sig5  sig6   sig7   sig8   sig9  \n",
       "0  True  False  True  False  False  False  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dataframe `correlations_df` here\n",
    "# YOUR CODE HERE\n",
    "correlations_df = df.select([fn.corr('f_'+str(i), \"target\").alias('c'+str(i)+'_target') for i in range(10)]\n",
    "                            # fn.corr calculate the correlation between features and target\n",
    "         +\n",
    "         [(fn.abs(fn.corr('f_'+str(i), \"target\"))>0.5).alias('sig'+str(i)) for i in range(10)])\n",
    "         # fn.abs takes the absolute values of correlations\n",
    "         # >0.5 gives us the boolean value of true when the absolute value of the correlation between features and target is greater than 0.5\n",
    "correlations_df.toPandas()\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "86a41f3db733560238662ea32ca87d16",
     "grade": true,
     "grade_id": "cell-ea3814c44cba8dcc",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"20 pts: Check that the dataframe has the correct columns and values. There could be hidden tests!\"\"\"\n",
    "# check column names\n",
    "column_names = ['c' + str(fi) + '_target' for fi in range(10)] + \\\n",
    "               ['sig' + str(fi) for fi in range(10)]\n",
    "\n",
    "# column's names and positions in the right order\n",
    "np.testing.assert_equal(correlations_df.columns, column_names)\n",
    "\n",
    "from pyspark.sql.types import DoubleType, BooleanType\n",
    "\n",
    "\n",
    "# the types are correct\n",
    "np.testing.assert_equal([type(f.dataType) for f in correlations_df.schema.fields], \n",
    "                        10*[DoubleType] + 10*[BooleanType])\n",
    "\n",
    "# the values are correct\n",
    "np.testing.assert_approx_equal(correlations_df.toPandas().sum().sum(), \n",
    "                               4.963039476979365,\n",
    "                               significant=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
