{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback\n",
    "99%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Willard Williamson <wewillia@syr.edu>\n",
    "- Faculty Assistant: Yash Pasar <yspasar@syr.edu>\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers from your classmates.  Short code snippets are allowed from the internet.  Code from the class text books or class provided code can be copied in its entirety.__\n",
    "- There could be tests in some cells (i.e., `assert` and `np.testing.` statements). These tests (if present) are used to grade your answers. **However, the professor and FAs could use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before submitting your work, remember to check for run time errors with the following procedure:\n",
    "`Kernel`$\\rightarrow$`Restart and Run All`.  All runtime errors will result in a minimum penalty of half off.\n",
    "- Data Bricks is the official class runtime environment so you should test your code on Data Bricks before submission.  If there is a runtime problem in the grading environment, we will try your code on Data Bricks before making a final grading decision.\n",
    "- All plots shall include a title, and axis labels.\n",
    "- Grading feedback cells are there for graders to provide feedback to students.  Don't change or remove grading feedback cells.\n",
    "- Don't add or remove files from your git repo.\n",
    "- Do not change file names in your repo.  This also means don't change the title of the ipython notebook.\n",
    "- You are free to add additional code cells around the cells marked `your code here`.\n",
    "- Students may use toPandas() to print the head of data frames.\n",
    "- __Only use spark, spark machine learning, spark data frames, RDD's, and map reduce to solve all problems unless instructed otherwise.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark Session and Spark Context\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "# Spark 1.6 (sparkContext on variable sc)\n",
    "# Spark 2.0 Dataframes\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# # # # #\n",
    "import seaborn as sns\n",
    "from pyspark.sql import functions as fn\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml import feature, regression, evaluation, Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete or change this cell\n",
    "\n",
    "import os\n",
    "\n",
    "# Define a function to determine if we are running on data bricks\n",
    "# Return true if running in the data bricks environment, false otherwise\n",
    "def is_databricks():\n",
    "    # get the databricks runtime version\n",
    "    db_env = os.getenv(\"DATABRICKS_RUNTIME_VERSION\")\n",
    "    \n",
    "    # if running on data bricks\n",
    "    if db_env != None:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Define a function to read the data file.  The full path data file name is constructed\n",
    "# by checking runtime environment variables to determine if the runtime environment is \n",
    "# databricks, or a student's personal computer.  The full path file name is then\n",
    "# constructed based on the runtime env.\n",
    "# \n",
    "# Params\n",
    "#   data_file_name: The base name of the data file to load\n",
    "# \n",
    "# Returns the full path file name based on the runtime env\n",
    "#\n",
    "def get_training_filename(data_file_name):    \n",
    "    # if running on data bricks\n",
    "    if is_databricks():\n",
    "        # build the full path file name assuming data brick env\n",
    "        full_path_name = \"/FileStore/tables/%s\" % data_file_name\n",
    "    # else the data is assumed to be in the same dir as this notebook\n",
    "    else:\n",
    "        # Assume the student is running on their own computer and load the data\n",
    "        # file from the same dir as this notebook\n",
    "        full_path_name = data_file_name\n",
    "    \n",
    "    # return the full path file name to the caller\n",
    "    return full_path_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Using the get_training_filename function defined in the cell above, read the sms_spam.csv file into a spark dataframe named spam_df.  There should be no empty columns in spam_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "spam_df = spark.read.csv(get_training_filename('sms_spam.csv'), header=True, inferSchema=True)\n",
    "# print(spam_df.printSchema())\n",
    "# spam_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|type|                text|\n",
      "+----+--------------------+\n",
      "| ham|Go until jurong p...|\n",
      "| ham|Ok lar... Joking ...|\n",
      "|spam|Free entry in 2 a...|\n",
      "| ham|U dun say so earl...|\n",
      "| ham|Nah I don't think...|\n",
      "+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "spam_df.show(5)\n",
    "print(spam_df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "Starting with spam_df, create a new dataframe named spam_df1.  Rename the spam_df type column to be named spam.  In the spam column, replace the string `spam` the with the integer 1 and the string `ham` with the integer 0.  Print the head and shape of spam_df1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The head of spam_df1 is:\n",
      "    spam                                                                                                                                                         text\n",
      "0  0     Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            \n",
      "1  0     Ok lar... Joking wif u oni...                                                                                                                              \n",
      "2  1     Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "3  0     U dun say so early hor... U c already then say...                                                                                                          \n",
      "4  0     Nah I don't think he goes to usf, he lives around here though                                                                                              \n",
      "\n",
      "\n",
      "The shape of spam_df1 is:  (5574, 2)\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "spam_df1 = spam_df.withColumnRenamed(\"type\", \"spam\")\n",
    "# method 2:\n",
    "# spam_df1 = spam_df.select(fn.col('type').alias('spam'), fn.col(\"text\"))\n",
    "\n",
    "# explore the spam_df1\n",
    "# spam_df1.select('spam').distinct().show()\n",
    "\n",
    "spam_df1 = spam_df1.withColumn(\"spam\",fn.when(fn.col(\"spam\")==\"ham\", 0).otherwise(1))\n",
    "print('The head of spam_df1 is:\\n',spam_df1.toPandas().head())\n",
    "print('\\n')\n",
    "print('The shape of spam_df1 is: ',(spam_df1.count(),len(spam_df1.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4827"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df1.where(fn.col('spam') == 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df1.where(fn.col('spam') == 1).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "Starting with spam_df1, create a new dataframe named spam_df2 with a new column named filtered_text by removing stop words from the text column in spam_df.  Print the head and shape of spam_df2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "\n",
    "# the tokenizer object\n",
    "# tokenizer = Tokenizer().setInputCol(\"text\")\\\n",
    "#   .setOutputCol(\"words\")\n",
    "tokenizer = RegexTokenizer().setGaps(False)\\\n",
    "  .setPattern(\"\\\\p{L}+\")\\\n",
    "  .setInputCol(\"text\")\\\n",
    "  .setOutputCol(\"words\")\n",
    "\n",
    "# we obtain the stop words from a website\n",
    "import requests\n",
    "stop_words = requests.get('http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words').text.split()\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "# the StopWordsRemover object\n",
    "sw_filter = StopWordsRemover()\\\n",
    "  .setStopWords(stop_words)\\\n",
    "  .setCaseSensitive(False)\\\n",
    "  .setInputCol(\"words\")\\\n",
    "  .setOutputCol(\"filtered_text\")\n",
    "\n",
    "# we now create a pipelined transformer\n",
    "swr_pipeline = Pipeline(stages=[tokenizer, sw_filter]).fit(spam_df1)\n",
    "# now we can make the transformation between the raw text and the filtered_text\n",
    "spam_df2=swr_pipeline.transform(spam_df1)\n",
    "# spam_df2=spam_df2.drop('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The head of spam_df2 is:\n",
      " Row(spam=0, text='Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', words=['go', 'until', 'jurong', 'point', 'crazy', 'available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', 'cine', 'there', 'got', 'amore', 'wat'], filtered_text=['jurong', 'point', 'crazy', 'available', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', 'cine', 'got', 'amore', 'wat'])\n",
      "\n",
      "\n",
      "The shape of spam_df2 is:  (5574, 4)\n"
     ]
    }
   ],
   "source": [
    "print('The head of spam_df2 is:\\n',spam_df2.head())\n",
    "print('\\n')\n",
    "print('The shape of spam_df2 is: ',(spam_df2.count(),len(spam_df2.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+--------------------+\n",
      "|spam|                text|               words|       filtered_text|\n",
      "+----+--------------------+--------------------+--------------------+\n",
      "|   0|Go until jurong p...|[go, until, juron...|[jurong, point, c...|\n",
      "|   0|Ok lar... Joking ...|[ok, lar, joking,...|[ok, lar, joking,...|\n",
      "+----+--------------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spam_df2.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "Create a new dataframe named spam_df3 starting with spam_df2.  Create a new column named tfidf by performing a term frequency / inverse document frequency transformation on the filtered_text column of spam_df2.<br>  \n",
    "\n",
    "- Print the head and shape of spam_df3.  \n",
    "- Print the top 10 most important words indicated by the TFIDF score.  \n",
    "- Print the 10 least important words as indicated by the TFIDF score.\n",
    "- Print the total number of columns in the TFIDF data in spam_df3\n",
    "- Print the number of rows in the TFIDF data in spam_df3\n",
    "- Based only on the number of rows and columns in the TFIDF data, do you expect the model to overfit.  Explain your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "# we will remove words that appear in 5 docs or less\n",
    "cv = CountVectorizer(minTF=1,minDF=5,vocabSize=2**17)\\\n",
    "  .setInputCol(\"filtered_text\")\\\n",
    "  .setOutputCol(\"tf\")\n",
    "\n",
    "from pyspark.ml.feature import IDF\n",
    "idf = IDF().setInputCol(\"tf\").setOutputCol(\"tfidf\")\n",
    "\n",
    "#cv_fitted=Pipeline(stages=[cv]).fit(spam_df2)\n",
    "\n",
    "#idf_fitted=Pipeline(stages=[cv_fitted,idf]).fit(spam_df2)\n",
    "\n",
    "idf_pipeline = Pipeline(stages=[cv,idf]).fit(spam_df2)\n",
    "\n",
    "spam_df3=idf_pipeline.transform(spam_df2)\n",
    "\n",
    "# spam_df3=spam_df3.drop('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>tf</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5569</td>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u. U have won the £750 Pound prize. 2 claim is easy, call 087187272008 NOW1! Only 10p per minute. BT-national-rate.</td>\n",
       "      <td>[this, is, the, nd, time, we, have, tried, contact, u, u, have, won, the, pound, prize, claim, is, easy, call, now, only, p, per, minute, bt, national, rate]</td>\n",
       "      <td>[nd, time, tried, contact, u, u, won, pound, prize, claim, easy, p, minute, bt, national, rate]</td>\n",
       "      <td>(2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n",
       "      <td>(3.7829118727107427, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.278940065610851, 0.0, 0.0, 0.0, 0.0, 3.4442640460362344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.934699714099176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.061699404860483, 4.183396339838003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5570</td>\n",
       "      <td>0</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>[will, ü, b, going, to, esplanade, fr, home]</td>\n",
       "      <td>[ü, b, going, esplanade, fr, home]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5020836169250606, 3.698793911171115, 0.0, 0.0, 0.0, 0.0, 3.514059807971776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.01092707948706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5571</td>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other suggestions?</td>\n",
       "      <td>[pity, was, in, mood, for, that, so, any, other, suggestions]</td>\n",
       "      <td>[pity, mood, suggestions]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5572</td>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free</td>\n",
       "      <td>[the, guy, did, some, bitching, but, i, acted, like, i, d, be, interested, in, buying, something, else, next, week, and, he, gave, it, to, us, for, free]</td>\n",
       "      <td>[guy, did, bitching, acted, like, d, interested, buying, week, gave, free]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.170726480970618, 0.0, 0.0, 0.0, 3.19232559277408, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.030927746193729, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8469241032167902, 0.0, 3.9165173950159855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5573</td>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>[rofl, its, true, to, its, name]</td>\n",
       "      <td>[rofl, true]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      spam                                                                                                                                                              text                                                                                                                                                          words                                                                                    filtered_text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         tf                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            tfidf\n",
       "5569  1     This is the 2nd time we have tried 2 contact u. U have won the £750 Pound prize. 2 claim is easy, call 087187272008 NOW1! Only 10p per minute. BT-national-rate.  [this, is, the, nd, time, we, have, tried, contact, u, u, have, won, the, pound, prize, claim, is, easy, call, now, only, p, per, minute, bt, national, rate]  [nd, time, tried, contact, u, u, won, pound, prize, claim, easy, p, minute, bt, national, rate]  (2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)  (3.7829118727107427, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.278940065610851, 0.0, 0.0, 0.0, 0.0, 3.4442640460362344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.934699714099176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.061699404860483, 4.183396339838003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)\n",
       "5570  0     Will ü b going to esplanade fr home?                                                                                                                              [will, ü, b, going, to, esplanade, fr, home]                                                                                                                   [ü, b, going, esplanade, fr, home]                                                               (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.5020836169250606, 3.698793911171115, 0.0, 0.0, 0.0, 0.0, 3.514059807971776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.01092707948706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)                              \n",
       "5571  0     Pity, * was in mood for that. So...any other suggestions?                                                                                                         [pity, was, in, mood, for, that, so, any, other, suggestions]                                                                                                  [pity, mood, suggestions]                                                                        (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)                                                                                      \n",
       "5572  0     The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free                                     [the, guy, did, some, bitching, but, i, acted, like, i, d, be, interested, in, buying, something, else, next, week, and, he, gave, it, to, us, for, free]      [guy, did, bitching, acted, like, d, interested, buying, week, gave, free]                       (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.170726480970618, 0.0, 0.0, 0.0, 3.19232559277408, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.030927746193729, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8469241032167902, 0.0, 3.9165173950159855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)               \n",
       "5573  0     Rofl. Its true to its name                                                                                                                                        [rofl, its, true, to, its, name]                                                                                                                               [rofl, true]                                                                                     (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...)                                                                                      "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spam_df3.toPandas().head()\n",
    "spam_df3.toPandas().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3 1.1 The head of spam_df3 is:\n",
      " Row(spam=0, text='Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', words=['go', 'until', 'jurong', 'point', 'crazy', 'available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', 'cine', 'there', 'got', 'amore', 'wat'], filtered_text=['jurong', 'point', 'crazy', 'available', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', 'cine', 'got', 'amore', 'wat'], tf=SparseVector(1550, {15: 1.0, 26: 1.0, 53: 1.0, 61: 1.0, 68: 1.0, 208: 1.0, 486: 1.0, 567: 1.0, 646: 1.0, 832: 1.0, 1065: 1.0, 1099: 1.0}), tfidf=SparseVector(1550, {15: 3.188, 26: 3.6493, 53: 3.9347, 61: 3.9913, 68: 4.1487, 208: 5.0425, 486: 5.6816, 567: 5.918, 646: 5.987, 832: 6.2282, 1065: 6.5466, 1099: 6.5466})) \n",
      "\n",
      "Q3 1.2 The shape of spam_df3 is:  (5574, 6)\n"
     ]
    }
   ],
   "source": [
    "# Print the head and shape of spam_df3.\n",
    "print('Q3 1.1 The head of spam_df3 is:\\n',spam_df3.head(),'\\n')\n",
    "print('Q3 1.2 The shape of spam_df3 is: ',(spam_df3.count(),len(spam_df3.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spam_df3.toPandas().loc[:1, ['tf', 'tfidf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tfidf): 1550\n",
      "len(vocabulary): 1550\n",
      "<class 'pyspark.ml.linalg.DenseVector'>\n",
      "(1550,)\n",
      "[1.89145594 2.36646613 2.6026     2.57631414 2.89594781 2.73716964\n",
      " 3.13298615 3.13298615 2.99125799 3.17072648 3.07308801 3.11665926\n",
      " 3.17931022 3.19232559 3.23242005 3.18796829 3.24615024 3.27894007\n",
      " 3.4555636  3.35304804 3.37902352 3.44989786 3.44426405 3.49614888\n",
      " 3.50208362 3.69879391 3.64931385 3.58262248 3.53845126 3.64244097\n",
      " 3.51405981 3.68440517 3.64244097 3.55087378 3.60216708 3.76623519\n",
      " 3.71339271 3.71339271 4.03092775 3.72077282 3.75085027 3.71339271\n",
      " 3.83855585 3.7282078  3.73569847 3.9165174  3.75851315 3.8469241\n",
      " 3.78976569 3.9165174 ]\n",
      "2.3664661322633966\n"
     ]
    }
   ],
   "source": [
    "vocabulary = idf_pipeline.stages[0].vocabulary\n",
    "tfidf = idf_pipeline.stages[1].idf.toArray()\n",
    "print(\"len(tfidf):\", len(tfidf))\n",
    "print(\"len(vocabulary):\", len(vocabulary))\n",
    "print(type(idf_pipeline.stages[1].idf))\n",
    "print(idf_pipeline.stages[1].idf.shape)\n",
    "print(idf_pipeline.stages[1].idf[:50])\n",
    "print(tfidf[1])\n",
    "tfidf_df = pd.DataFrame({'word': vocabulary, 'tfidf': tfidf})\n",
    "# Print the total number of columns in the TFIDF data in spam_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3 2. The top 10 most important words indicated by the TFIDF score are:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1549</td>\n",
       "      <td>geeee</td>\n",
       "      <td>6.834288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1396</td>\n",
       "      <td>flat</td>\n",
       "      <td>6.834288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1408</td>\n",
       "      <td>sam</td>\n",
       "      <td>6.834288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1407</td>\n",
       "      <td>nat</td>\n",
       "      <td>6.834288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1406</td>\n",
       "      <td>bcm</td>\n",
       "      <td>6.834288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1405</td>\n",
       "      <td>inclusive</td>\n",
       "      <td>6.834288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1404</td>\n",
       "      <td>arrested</td>\n",
       "      <td>6.834288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1403</td>\n",
       "      <td>nw</td>\n",
       "      <td>6.834288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1401</td>\n",
       "      <td>broke</td>\n",
       "      <td>6.834288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>asleep</td>\n",
       "      <td>6.834288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word     tfidf\n",
       "1549  geeee      6.834288\n",
       "1396  flat       6.834288\n",
       "1408  sam        6.834288\n",
       "1407  nat        6.834288\n",
       "1406  bcm        6.834288\n",
       "1405  inclusive  6.834288\n",
       "1404  arrested   6.834288\n",
       "1403  nw         6.834288\n",
       "1401  broke      6.834288\n",
       "1400  asleep     6.834288"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the top 10 most important words indicated by the TFIDF score.\n",
    "print('Q3 2. The top 10 most important words indicated by the TFIDF score are:\\n')\n",
    "tfidf_df.sort_values('tfidf',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3 3. The 10 least important words indicated by the TFIDF score are:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>1.891456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>s</td>\n",
       "      <td>2.366466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>m</td>\n",
       "      <td>2.576314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>2.602600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>just</td>\n",
       "      <td>2.737170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ur</td>\n",
       "      <td>2.895948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>ok</td>\n",
       "      <td>2.991258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>ll</td>\n",
       "      <td>3.073088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>know</td>\n",
       "      <td>3.116659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>lt</td>\n",
       "      <td>3.132986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word     tfidf\n",
       "0   u     1.891456\n",
       "1   s     2.366466\n",
       "3   m     2.576314\n",
       "2   t     2.602600\n",
       "5   just  2.737170\n",
       "4   ur    2.895948\n",
       "8   ok    2.991258\n",
       "10  ll    3.073088\n",
       "11  know  3.116659\n",
       "7   lt    3.132986"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the 10 least important words as indicated by the TFIDF score.\n",
    "print('Q3 3. The 10 least important words indicated by the TFIDF score are:\\n')\n",
    "tfidf_df.sort_values('tfidf').head(10)\n",
    "# tfidf_df.sort_values(abs('tfidf')).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3 4. The total number of columns in the TFIDF data in spam_df3 is:\n",
      " 1550\n",
      "Q3 5. The number of rows in the TFIDF data in spam_df3 is:\n",
      " 5574\n"
     ]
    }
   ],
   "source": [
    "# Print the total number of columns in the TFIDF data in spam_df3\n",
    "# Print the number of rows in the TFIDF data in spam_df3\n",
    "\n",
    "print('Q3 4. The total number of columns in the TFIDF data in spam_df3 is:\\n',len(tfidf))\n",
    "# Print the number of rows in the TFIDF data in spam_df3\n",
    "print('Q3 5. The number of rows in the TFIDF data in spam_df3 is:\\n',spam_df3.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your model overfit explanation here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based only on the number of rows and columns in the TFIDF data, I expect the model to overfit. <br/>\n",
    "When the number of features is bigger than that of training examples, the model tends to overfit. Though in our dataset, the number of features is smaller than that of training examples, we still have too many features. Since the variance of a regression model is directly proportional to the number of features in the data set: as number of  features increases, model variance increases. High variance means that our learning algorithm varies a lot depending on the training data. This is bad because it means our algorithm is probably not robust to noise for example and it will fail to generalize to new examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback\n",
    "-1 You shouldn't arbitrarily set the vocabulary size unless you know the true vocab size.  In the class notebook where this code came from, the real vocab size is less than 2**17."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "Create a pipeline named pipe1 capable of predicting ham or spam using logistic regression using spam_df3 as input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr=LogisticRegression().\\\n",
    "    setLabelCol('spam').\\\n",
    "    setFeaturesCol('tfidf').\\\n",
    "    setRegParam(0.0).\\\n",
    "    setMaxIter(100).\\\n",
    "    setElasticNetParam(0.)\n",
    "pipe1=Pipeline(stages=[lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "Fit pipe1 using a [CrossValidator](https://spark.apache.org/docs/2.2.0/api/python/pyspark.ml.html#pyspark.ml.tuning.CrossValidator) object with the number of cross validation folds = 3.  Score the model using a [BinaryClassificationEvaluator](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html) using ROC AUC as the metric.  Name the cross validator object cv1 and the fitted cross validator object fitted_cv1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, testing_df = spam_df3.randomSplit([0.8, 0.2], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a grid search ParamGridBuilder object. \n",
    "# elasticNetParam and regParam are 0\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.elasticNetParam, [0.]) \\\n",
    "    .addGrid(lr.regParam, [0.]) \\\n",
    "    .build()\n",
    "# The length of the grid is 1 because it implements all combinations of elasticNetParam (1 option) and regParam (1 options).\n",
    "len(paramGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# Define an evaluator \n",
    "evaluator = BinaryClassificationEvaluator(labelCol=lr.getLabelCol(), rawPredictionCol=lr.getRawPredictionCol())\n",
    "# create a CrossValidator object with the number of cross validation folds = 3\n",
    "cv1=CrossValidator(estimator=pipe1,\n",
    "                   estimatorParamMaps=paramGrid, \n",
    "                   evaluator=evaluator,\n",
    "                   numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit cv1 using the CrossValidator object with the number of cross validation folds = 3\n",
    "fitted_cv1 = cv1.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      avg(correct)|\n",
      "+------------------+\n",
      "|0.9564056939501779|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's look at the performance\n",
    "fitted_cv1.transform(testing_df).select(fn.expr('float(prediction=spam)').alias('correct')).select(fn.avg('correct')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9508117183659676"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score the model using a BinaryClassificationEvaluator using ROC AUC as the metric.\n",
    "evaluator.evaluate(fitted_cv1.transform(testing_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'areaUnderROC'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the Evaluator gives us AUC as the metric.\n",
    "evaluator.getMetricName()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback\n",
    "You don't have to split into train and test though it is useful to have a test set to compare models like random forest to logistic regression. That being said, there is nothing wrong with splitting either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "Print the cross validation AUC score from fitted_cv1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9508117183659676"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score the model using a BinaryClassificationEvaluator using ROC AUC as the metric.\n",
    "evaluator.evaluate(fitted_cv1.transform(testing_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'areaUnderROC'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the Evaluafrom pyspark.mllib.evaluation import BinaryClassificationMetricstor gives us AUC as the metric.\n",
    "evaluator.getMetricName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999229319178791"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the cross validation AUC score from fitted_cv1.\n",
    "auc = fitted_cv1.bestModel.stages[-1].summary.areaUnderROC\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7\n",
    "Create a ROC scatter plot from fitted_pipe1 TPR/FPR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = fitted_cv1.bestModel.stages[-1].summary.roc\n",
    "# method 2:\n",
    "# fpr = fitted_cv1.bestModel.stages[-1].summary.roc.select('FPR').toPandas()\n",
    "# tpr = fitted_cv1.bestModel.stages[-1].summary.roc.select('TPR').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code here\n",
    "roc.select('FPR','TPR'). \\\n",
    " toPandas().plot(x='FPR',y='TPR',kind='scatter', \\\n",
    "                                 color='steelblue',alpha=0.5, \\\n",
    "                                 title=\"ROC scatter plot of fitted_pipe1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8\n",
    "Create a new cross validator object named cv2 similar to cv1 but this time add a ParamGridBuilder.  Define a grid of elastic net regularization parameters. Fit cv2 and name the resulting fitted cross validator fitted_cv2.  The number of parameters in your grid should be limited such that it runs in a reasonable amount of time (around 5 to 10 minutes max).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# elasticNetParam corresponds to α and regParam corresponds to λ\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.elasticNetParam, [0.01, 0.02, 0.2]) \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.02, 0.05, 0.2]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# Create a new cross validator object named cv2  \n",
    "cv2=CrossValidator(estimator=pipe1,\n",
    "                   estimatorParamMaps=paramGrid, \n",
    "                   evaluator=evaluator,\n",
    "                   numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit cv2 and name the resulting fitted cross validator fitted_cv2. \n",
    "fitted_cv2 = cv2.fit(training_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 9\n",
    "- Print the resulting AUC from fitted_cv2. \n",
    "- Print the best model's L1 and L2 regularization parameters\n",
    "- Analyze the L1 feature selection:\n",
    "    - Print the total number of features\n",
    "    - Print the number of features that L1 regularization eliminated\n",
    "    - If any features were eliminated, print a sample of 10 words that were eliminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the resulting AUC from fitted_cv2 is:\n",
      "0.9887834119622441\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# Print the resulting AUC from fitted_cv2.\n",
    "print('the resulting AUC from fitted_cv2 is:') \n",
    "print(evaluator.evaluate(fitted_cv2.transform(testing_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paramGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model 1\n",
      "Fitting model 2\n",
      "Fitting model 3\n",
      "Fitting model 4\n",
      "Fitting model 5\n",
      "Fitting model 6\n",
      "Fitting model 7\n",
      "Fitting model 8\n",
      "Fitting model 9\n",
      "Fitting model 10\n",
      "Fitting model 11\n",
      "Fitting model 12\n"
     ]
    }
   ],
   "source": [
    "all_models = []\n",
    "for j in range(len(paramGrid)):\n",
    "    print(\"Fitting model {}\".format(j+1))\n",
    "    model = pipe1.fit(training_df, paramGrid[j])\n",
    "    all_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the accuracy of each of them:\n",
    "accuracies = [m.\\\n",
    "    transform(testing_df).\\\n",
    "    select(fn.avg(fn.expr('float(spam = prediction)')).alias('accuracy')).\\\n",
    "    first().\\\n",
    "    accuracy for m in all_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9777580071174378,\n",
       " 0.9741992882562278,\n",
       " 0.9724199288256228,\n",
       " 0.9653024911032029,\n",
       " 0.9768683274021353,\n",
       " 0.9741992882562278,\n",
       " 0.9733096085409253,\n",
       " 0.9626334519572953,\n",
       " 0.9750889679715302,\n",
       " 0.9715302491103203,\n",
       " 0.9635231316725978,\n",
       " 0.8932384341637011]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{Param(parent='LogisticRegression_c1352b0e1ce6', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.01,\n",
       "  Param(parent='LogisticRegression_c1352b0e1ce6', name='regParam', doc='regularization parameter (>= 0).'): 0.01},\n",
       " {Param(parent='LogisticRegression_c1352b0e1ce6', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.01,\n",
       "  Param(parent='LogisticRegression_c1352b0e1ce6', name='regParam', doc='regularization parameter (>= 0).'): 0.02},\n",
       " {Param(parent='LogisticRegression_c1352b0e1ce6', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.01,\n",
       "  Param(parent='LogisticRegression_c1352b0e1ce6', name='regParam', doc='regularization parameter (>= 0).'): 0.05},\n",
       " {Param(parent='LogisticRegression_c1352b0e1ce6', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.01,\n",
       "  Param(parent='LogisticRegression_c1352b0e1ce6', name='regParam', doc='regularization parameter (>= 0).'): 0.2},\n",
       " {Param(parent='LogisticRegression_c1352b0e1ce6', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.02,\n",
       "  Param(parent='LogisticRegression_c1352b0e1ce6', name='regParam', doc='regularization parameter (>= 0).'): 0.01},\n",
       " {Param(parent='LogisticRegression_c1352b0e1ce6', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.02,\n",
       "  Param(parent='LogisticRegression_c1352b0e1ce6', name='regParam', doc='regularization parameter (>= 0).'): 0.02},\n",
       " {Param(parent='LogisticRegression_c1352b0e1ce6', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.02,\n",
       "  Param(parent='LogisticRegression_c1352b0e1ce6', name='regParam', doc='regularization parameter (>= 0).'): 0.05},\n",
       " {Param(parent='LogisticRegression_c1352b0e1ce6', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.02,\n",
       "  Param(parent='LogisticRegression_c1352b0e1ce6', name='regParam', doc='regularization parameter (>= 0).'): 0.2},\n",
       " {Param(parent='LogisticRegression_c1352b0e1ce6', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2,\n",
       "  Param(parent='LogisticRegression_c1352b0e1ce6', name='regParam', doc='regularization parameter (>= 0).'): 0.01},\n",
       " {Param(parent='LogisticRegression_c1352b0e1ce6', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2,\n",
       "  Param(parent='LogisticRegression_c1352b0e1ce6', name='regParam', doc='regularization parameter (>= 0).'): 0.02},\n",
       " {Param(parent='LogisticRegression_c1352b0e1ce6', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2,\n",
       "  Param(parent='LogisticRegression_c1352b0e1ce6', name='regParam', doc='regularization parameter (>= 0).'): 0.05},\n",
       " {Param(parent='LogisticRegression_c1352b0e1ce6', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2,\n",
       "  Param(parent='LogisticRegression_c1352b0e1ce6', name='regParam', doc='regularization parameter (>= 0).'): 0.2}]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model index = 0\n",
      "0.9777580071174378\n",
      "[LogisticRegressionModel: uid = LogisticRegression_c1352b0e1ce6, numClasses = 2, numFeatures = 1550]\n"
     ]
    }
   ],
   "source": [
    "best_model_idx = np.argmax(accuracies)\n",
    "print(\"best model index =\", best_model_idx)\n",
    "best_model = all_models[best_model_idx]\n",
    "print(accuracies[best_model_idx])\n",
    "print(best_model.stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_c1352b0e1ce6', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.01,\n",
       " Param(parent='LogisticRegression_c1352b0e1ce6', name='regParam', doc='regularization parameter (>= 0).'): 0.01}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the best model's L1 and L2 regularization parameters\n",
    "#So the best model we found has the following parameters\n",
    "paramGrid[best_model_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model's Elastic Net regularization parameter is:\n",
      " 0.01\n",
      "best model's L1 regularization parameter is:\n",
      " 0.01\n",
      "best model's L2 regularization parameters is:\n",
      " 0.99\n"
     ]
    }
   ],
   "source": [
    "# Print the best model's L1 and L2 regularization parameters\n",
    "# elasticNetParam corresponds to α \n",
    "# regParam corresponds to λ\n",
    "# print(best_model.stages[0].getElasticNetParam())\n",
    "# print(best_model.stages[0].getRegParam())\n",
    "print(\"best model's Elastic Net regularization parameter is:\\n\",best_model.stages[0]._java_obj.getElasticNetParam())\n",
    "print(\"best model's L1 regularization parameter is:\\n\",best_model.stages[0]._java_obj.getRegParam())\n",
    "print(\"best model's L2 regularization parameters is:\\n\",(1-best_model.stages[0]._java_obj.getRegParam()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of features is:\n",
      " 1550\n"
     ]
    }
   ],
   "source": [
    "# Print the total number of features \n",
    "en_weights = best_model.stages[0].coefficients.toArray()\n",
    "en_weights = fitted_cv2.bestModel.stages[0].coefficients.toArray()\n",
    "print(\"The total number of features is:\\n\",en_weights.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_coeffs_df = pd.DataFrame({'word': vocabulary, 'weight': en_weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of features that L1 regularization eliminated is:\n",
      " 285\n"
     ]
    }
   ],
   "source": [
    "# Print the number of features that L1 regularization eliminated\n",
    "print(\"the number of features that L1 regularization eliminated is:\\n\",en_coeffs_df.query('weight == 0.0').shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a sample of 10 words that were eliminated:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>s</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>just</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>day</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>want</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>r</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>hi</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>make</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>ve</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>e</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>let</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  weight\n",
       "1   s     0.0   \n",
       "5   just  0.0   \n",
       "14  day   0.0   \n",
       "20  want  0.0   \n",
       "27  r     0.0   \n",
       "42  hi    0.0   \n",
       "64  make  0.0   \n",
       "67  ve    0.0   \n",
       "68  e     0.0   \n",
       "88  let   0.0   "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a sample of 10 words that were eliminated\n",
    "print(\"a sample of 10 words that were eliminated:\")\n",
    "en_coeffs_df.query('weight == 0.0').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback\n",
    "-5 Multiple problems<br>\n",
    "Runtime error.  Had to add ._java_obj to fix get regularization and elastic net param runtime errors.<br>\n",
    "Incorrect regularization param.  The reg param is shared between L1 and L2.  Alpha and 1-alpha (the elastic net param is alpha) is multiplied by the reg param to obtain L1 and L2 multipliers.<br>\n",
    "Why did you retrain all the models?  The L1 and L2 data should have been extracted from fitted_cv2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 10\n",
    "Analyze the best model weights in fitted_cv2.  Print the 10 words that contribute the most to predicting spam.  Print the 10 words that contribute the least to predicting spam.  Do the words make sense?  Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "weights=best_model.stages[0].coefficients.toArray()\n",
    "coeffs_df = pd.DataFrame({'word': vocabulary, 'weight': weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights=bestModel.stages[0].coefficients.toArray()\n",
    "# coeffs_df = pd.DataFrame({'word': vocabulary, 'weight': weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 words that contribute the most to predicting spam are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>979</td>\n",
       "      <td>freephone</td>\n",
       "      <td>0.769442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1286</td>\n",
       "      <td>hp</td>\n",
       "      <td>0.716852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>services</td>\n",
       "      <td>0.704914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>ringtone</td>\n",
       "      <td>0.637840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>new</td>\n",
       "      <td>0.611330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1246</td>\n",
       "      <td>ls</td>\n",
       "      <td>0.592590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>announcement</td>\n",
       "      <td>0.584268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>p</td>\n",
       "      <td>0.577129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>message</td>\n",
       "      <td>0.561275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>724</td>\n",
       "      <td>ac</td>\n",
       "      <td>0.537224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word    weight\n",
       "979   freephone     0.769442\n",
       "1286  hp            0.716852\n",
       "490   services      0.704914\n",
       "256   ringtone      0.637840\n",
       "43    new           0.611330\n",
       "1246  ls            0.592590\n",
       "1240  announcement  0.584268\n",
       "22    p             0.577129\n",
       "70    message       0.561275\n",
       "724   ac            0.537224"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the 10 words that contribute the most to predicting spam\n",
    "print(\"The 10 words that contribute the most to predicting spam are:\")\n",
    "coeffs_df.sort_values('weight', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 words that contribute the least to predicting spam are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>988</td>\n",
       "      <td>fullonsms</td>\n",
       "      <td>-0.332357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>811</td>\n",
       "      <td>voice</td>\n",
       "      <td>-0.269194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>tel</td>\n",
       "      <td>-0.257378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>743</td>\n",
       "      <td>remove</td>\n",
       "      <td>-0.246553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1095</td>\n",
       "      <td>liked</td>\n",
       "      <td>-0.240964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>joke</td>\n",
       "      <td>-0.220829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1055</td>\n",
       "      <td>list</td>\n",
       "      <td>-0.212930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1432</td>\n",
       "      <td>wks</td>\n",
       "      <td>-0.198028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1533</td>\n",
       "      <td>atm</td>\n",
       "      <td>-0.195310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1118</td>\n",
       "      <td>share</td>\n",
       "      <td>-0.193607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word    weight\n",
       "988   fullonsms -0.332357\n",
       "811   voice     -0.269194\n",
       "575   tel       -0.257378\n",
       "743   remove    -0.246553\n",
       "1095  liked     -0.240964\n",
       "1125  joke      -0.220829\n",
       "1055  list      -0.212930\n",
       "1432  wks       -0.198028\n",
       "1533  atm       -0.195310\n",
       "1118  share     -0.193607"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The 10 words that contribute the least to predicting spam are:\")\n",
    "coeffs_df.sort_values('weight',ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your comments here: <br/>\n",
    "<br/>\n",
    "For the 10 words that contribute the most to predicting spam, some of them make sense to me. <br/>For example, words like \"freephone\",\"sale\",\"services\",\"new\" are commonly used word in SMS advertising. While word \"http\" are used in scam SMSs to direct the SMS receivers to some suspicious website.<br/>\n",
    "<br/>\n",
    "For the 10 words that contribute the least to predicting spam. They make sense to me too. <br/>\n",
    "I think the words that contribute the least to predicting spam would be some everyday vocabulary and most of these words are common expressions. <br/>\n",
    "However, the word \"fullonsms\" is an internet based portal which allows the customer to send free and unlimited messaging service to any mobile phone around India. I do not think this word is an everyday word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra Credit (5 pts)**  This question is optional.  If you choose to answer this question, you will earn 5 extra credit points.  If you choose not to answer this question, no points will be deducted from your score.  Solve the following equation for $c$ symbolically using the python sympy package.  Convert the solved symbolic solution to a latex format (this can be done with a pyton call), then populate the solution cell with the resulting latex code so that your solution shows up symbolically similar the equation below.\n",
    "\n",
    "$$c g - c h + e \\left(a + 1\\right)^{b} - \\frac{d \\left(\\left(a + 1\\right)^{b} - 1\\right)}{a} + \\frac{f \\left(\\left(a + 1\\right)^{b} - 1\\right)}{a} = 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not delete or change this cell\n",
    "\n",
    "# if running on data bricks\n",
    "if is_databricks():\n",
    "    # install sympy\n",
    "    dbutils.library.installPyPI\n",
    "    dbutils.library.installPyPI('sympy')\n",
    "    print(dbutils.library.list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import sympy\n",
    "from sympy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d,e,f,g,h=symbols('a,b,c,d,e,f,g,h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# c*g-c*h+e*((a+1)**b)-((d*((a+1)**b-1))/a)-((f*((a+1)**b-1))/a)\n",
    "solve(c*g-c*h+e*((a+1)**b)-(d*((a+1)**b-1)/a)+(f*((a+1)**b-1)/a),c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c=(-a*e*(a + 1)**b + d*(a + 1)**b - d - f*(a + 1)**b + f)/(a*(g - h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sympy.print_latex(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your latex output here such that a human readable equation is displayed for grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$c=\\frac{- a e \\left(a + 1\\right)^{b} + d \\left(a + 1\\right)^{b} - d - f \\left(a + 1\\right)^{b} + f}{a \\left(g - h\\right)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback\n",
    "+5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
